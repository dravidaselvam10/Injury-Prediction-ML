{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6361c320-30e5-42bb-91e5-b08264b043b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# Deep Learning (BiLSTM)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "# Notebook settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "INJURY_DATA_PATH = \"injury_data.csv\"\n",
    "NFL_DATA_PATH = \"nfl_injuries_2013_2023.csv\"\n",
    "\n",
    "TARGET_COL_TABULAR = \"injury\"  # Cross-sport target\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6661f327-cbf5-443c-b6c2-6f77caf70560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfl_week_to_date(season, week):\n",
    "    \"\"\"\n",
    "    Approximates NFL Week 1 as September 1st of the season year.\n",
    "    \"\"\"\n",
    "    base = datetime(season, 9, 1)\n",
    "    return base + timedelta(days=(week - 1) * 7)\n",
    "\n",
    "def load_sportA(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"Player_Age\": \"age\",\n",
    "        \"Player_Weight\": \"weight\",\n",
    "        \"Player_Height\": \"height\",\n",
    "        \"Previous_Injuries\": \"prev_injuries\",\n",
    "        \"Training_Intensity\": \"workload\",\n",
    "        \"Recovery_Time\": \"recovery_time\",\n",
    "        \"Likelihood_of_Injury\": \"injury\"\n",
    "    })\n",
    "\n",
    "    df[\"sport\"] = \"synthetic\"\n",
    "\n",
    "    # Pseudo-date\n",
    "    base_date = datetime(2010, 1, 1)\n",
    "    df[\"date\"] = [base_date + timedelta(days=i) for i in range(len(df))]\n",
    "\n",
    "    df[\"player_id\"] = [\"SYN_\" + str(i) for i in range(len(df))]\n",
    "\n",
    "    keep_A = [\n",
    "        \"player_id\", \"date\", \"sport\", \"injury\", \"workload\",\n",
    "        \"age\", \"weight\", \"height\", \"prev_injuries\", \"recovery_time\"\n",
    "    ]\n",
    "    \n",
    "    return df[keep_A]\n",
    "\n",
    "\n",
    "def load_sportB(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"player_id\"] = df[\"gsis_id\"]\n",
    "    df[\"date\"] = df.apply(\n",
    "        lambda r: nfl_week_to_date(r[\"season\"], r[\"week\"]), axis=1\n",
    "    )\n",
    "\n",
    "    df[\"injury\"] = df[\"report_status\"].isin([\"Out\", \"Doubtful\"]).astype(int)\n",
    "\n",
    "    practice_map = {\n",
    "        \"Full Participation in Practice\": 1.0,\n",
    "        \"Limited Participation in Practice\": 0.5,\n",
    "        \"Did Not Participate In Practice\": 0.0\n",
    "    }\n",
    "    df[\"workload\"] = df[\"practice_status\"].map(practice_map)\n",
    "\n",
    "    df[\"sport\"] = \"NFL\"\n",
    "\n",
    "    keep_B = [\n",
    "        \"player_id\", \"date\", \"sport\", \"injury\", \"workload\",\n",
    "        \"team\", \"position\", \"season\", \"week\",\n",
    "        \"report_status\", \"practice_status\"\n",
    "    ]\n",
    "\n",
    "    return df[keep_B].sort_values([\"player_id\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde327f7-aebc-4cf7-8f5d-47b864defb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all():\n",
    "    dfA = load_sportA(\"D://0 GIM Studies//MLBA//project//injury_data.csv\") # Modify according to path \n",
    "    dfB = load_sportB(\"D://0 GIM Studies//MLBA//project//nfl_injuries_2013_2023.csv\") # Modify according to path \n",
    "    return pd.concat([dfA, dfB], ignore_index=True)\n",
    "\n",
    "df = load_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641c64be-c9fb-449b-ba31-c62ce251353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_days_since_last_injury(df):\n",
    "    df = df.sort_values([\"player_id\", \"date\"])\n",
    "    df[\"days_since_last_injury\"] = np.nan\n",
    "\n",
    "    for pid, sub in df.groupby(\"player_id\"):\n",
    "        last_date = None\n",
    "        for idx, row in sub.iterrows():\n",
    "            df.loc[idx, \"days_since_last_injury\"] = np.nan if last_date is None else (row[\"date\"] - last_date).days\n",
    "            if row[\"injury\"] == 1:\n",
    "                last_date = row[\"date\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_rolling_features(df):\n",
    "    df = df.sort_values([\"player_id\", \"date\"])\n",
    "\n",
    "    df[\"rolling_injuries_4w\"] = (\n",
    "        df.groupby(\"player_id\")[\"injury\"]\n",
    "        .rolling(window=5, min_periods=1).sum()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[\"rolling_workload_4w\"] = (\n",
    "        df.groupby(\"player_id\")[\"workload\"]\n",
    "        .rolling(window=5, min_periods=1).mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_injury_history(df):\n",
    "    df = df.sort_values([\"player_id\", \"date\"])\n",
    "    df[\"injuries_last_90d\"] = np.nan\n",
    "\n",
    "    for pid, sub in df.groupby(\"player_id\"):\n",
    "        idx = sub.index\n",
    "        for i in range(len(sub)):\n",
    "            current_date = sub.iloc[i][\"date\"]\n",
    "            past = sub[(sub[\"date\"] >= current_date - timedelta(days=90)) &\n",
    "                       (sub[\"date\"] < current_date)]\n",
    "            df.loc[idx[i], \"injuries_last_90d\"] = past[\"injury\"].sum()\n",
    "\n",
    "    return df\n",
    "\n",
    "def compute_future_injury(df):\n",
    "    df = df.sort_values([\"player_id\", \"date\"])\n",
    "    df[\"future_injury_next_week\"] = 0\n",
    "\n",
    "    for pid, sub in df.groupby(\"player_id\"):\n",
    "        idx = sub.index\n",
    "        for i in range(len(sub)):\n",
    "            current = sub.iloc[i][\"date\"]\n",
    "            next_week = current + timedelta(days=7)\n",
    "            future = sub[(sub[\"date\"] > current) & (sub[\"date\"] <= next_week)][\"injury\"].any()\n",
    "            df.loc[idx[i], \"future_injury_next_week\"] = int(future)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d210136f-5786-4303-8f49-eec709bd2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sport</th>\n",
       "      <th>injury</th>\n",
       "      <th>workload</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>prev_injuries</th>\n",
       "      <th>recovery_time</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>report_status</th>\n",
       "      <th>practice_status</th>\n",
       "      <th>days_since_last_injury</th>\n",
       "      <th>injuries_last_90d</th>\n",
       "      <th>rolling_injuries_4w</th>\n",
       "      <th>rolling_workload_4w</th>\n",
       "      <th>future_injury_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>00-0000585</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>NFL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Out</td>\n",
       "      <td>Did Not Participate In Practice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>00-0000585</td>\n",
       "      <td>2013-09-08</td>\n",
       "      <td>NFL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Out</td>\n",
       "      <td>Did Not Participate In Practice</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>00-0000585</td>\n",
       "      <td>2013-09-15</td>\n",
       "      <td>NFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>Limited Participation in Practice</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>00-0000585</td>\n",
       "      <td>2013-09-22</td>\n",
       "      <td>NFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>Limited Participation in Practice</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>00-0000585</td>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>NFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>Limited Participation in Practice</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_id       date sport  injury  workload  age  weight  height  \\\n",
       "1000  00-0000585 2013-09-01   NFL       1       0.0  NaN     NaN     NaN   \n",
       "1001  00-0000585 2013-09-08   NFL       1       0.0  NaN     NaN     NaN   \n",
       "1002  00-0000585 2013-09-15   NFL       0       0.5  NaN     NaN     NaN   \n",
       "1003  00-0000585 2013-09-22   NFL       0       0.5  NaN     NaN     NaN   \n",
       "1004  00-0000585 2013-09-29   NFL       0       0.5  NaN     NaN     NaN   \n",
       "\n",
       "      prev_injuries  recovery_time team position  season  week report_status  \\\n",
       "1000            NaN            NaN  DEN       CB  2013.0   1.0           Out   \n",
       "1001            NaN            NaN  DEN       CB  2013.0   2.0           Out   \n",
       "1002            NaN            NaN  DEN       CB  2013.0   3.0  Questionable   \n",
       "1003            NaN            NaN  DEN       CB  2013.0   4.0  Questionable   \n",
       "1004            NaN            NaN  DEN       CB  2013.0   5.0  Questionable   \n",
       "\n",
       "                        practice_status  days_since_last_injury  \\\n",
       "1000    Did Not Participate In Practice                     NaN   \n",
       "1001    Did Not Participate In Practice                     7.0   \n",
       "1002  Limited Participation in Practice                     7.0   \n",
       "1003  Limited Participation in Practice                    14.0   \n",
       "1004  Limited Participation in Practice                    21.0   \n",
       "\n",
       "      injuries_last_90d  rolling_injuries_4w  rolling_workload_4w  \\\n",
       "1000                0.0                  1.0             0.000000   \n",
       "1001                1.0                  2.0             0.000000   \n",
       "1002                2.0                  2.0             0.166667   \n",
       "1003                2.0                  2.0             0.250000   \n",
       "1004                2.0                  2.0             0.300000   \n",
       "\n",
       "      future_injury_next_week  \n",
       "1000                        1  \n",
       "1001                        0  \n",
       "1002                        0  \n",
       "1003                        0  \n",
       "1004                        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engineer_all(df):\n",
    "    df = compute_days_since_last_injury(df)\n",
    "    df = compute_injury_history(df)\n",
    "    df = compute_rolling_features(df)\n",
    "    df = compute_future_injury(df)\n",
    "    return df\n",
    "\n",
    "df_eng = engineer_all(df)\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832e40f8-8d7b-4fce-8d1c-4ef5b82980f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41757, 8948, 8948)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_split(df, target):\n",
    "    df = df[~df[target].isna()]\n",
    "    df = df.sort_values(\"date\")\n",
    "\n",
    "    n = len(df)\n",
    "    t1 = int(n * TRAIN_RATIO)\n",
    "    t2 = int(n * (TRAIN_RATIO + VAL_RATIO))\n",
    "\n",
    "    return df.iloc[:t1], df.iloc[t1:t2], df.iloc[t2:]\n",
    "\n",
    "df_train, df_val, df_test = time_split(df_eng, TARGET_COL_TABULAR)\n",
    "(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a00f00a-0b49-4577-8f72-b0dba7606693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    # Strip whitespace from all object columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Replace bad tokens\n",
    "    BAD = set([\"nan\", \"NaN\", \"NAN\", \"None\", \"NONE\", \"NULL\", \"\", \" \", \"\\r\", \"\\n\", \"\\r\\n\", \"\\r\\n    \"])\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].apply(lambda x: \"Unknown\" if x in BAD else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to all splits after feature engineering\n",
    "df_train = clean_dataframe(df_train.copy())\n",
    "df_val   = clean_dataframe(df_val.copy())\n",
    "df_test  = clean_dataframe(df_test.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9e33a7-2fe0-4473-907f-8998e85f284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tabular(df_train, df_val, df_test, target):\n",
    "    drop_cols = [\"player_id\", \"date\"]\n",
    "\n",
    "    numeric = [c for c in df_train.columns if df_train[c].dtype != 'object' and c not in drop_cols + [target]]\n",
    "    categorical = [c for c in df_train.columns if c not in numeric + drop_cols + [target]]\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_train = pre.fit_transform(df_train[numeric + categorical])\n",
    "    X_val   = pre.transform(df_val[numeric + categorical])\n",
    "    X_test  = pre.transform(df_test[numeric + categorical])\n",
    "\n",
    "    y_train = df_train[target].values\n",
    "    y_val   = df_val[target].values\n",
    "    y_test  = df_test[target].values\n",
    "\n",
    "    feature_names = numeric + list(pre.named_transformers_[\"cat\"].get_feature_names_out(categorical))\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, pre, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3527100f-6d98-469f-894f-2843297526eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train):\n",
    "    models = {\n",
    "        \"LogReg\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=300, class_weight=\"balanced\", random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_estimators=400, learning_rate=0.05, max_depth=5,\n",
    "            subsample=0.8, colsample_bytree=0.8, eval_metric=\"logloss\")\n",
    "    }\n",
    "    for m in models.values():\n",
    "        m.fit(X_train, y_train)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49ea96-7a1b-4b9d-b47f-8f80b0bf988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X)[:,1]\n",
    "    except:\n",
    "        y_proba = y_pred.astype(float)\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y, y_pred),\n",
    "        \"Precision\": precision_score(y, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y, y_pred, zero_division=0),\n",
    "        \"ROC-AUC\": roc_auc_score(y, y_proba) if len(set(y)) > 1 else np.nan\n",
    "    }, confusion_matrix(y, y_pred)\n",
    "\n",
    "results_tab = {}\n",
    "cms_tab = {}\n",
    "\n",
    "for name, model in models_tab.items():\n",
    "    metrics, cm = evaluate(model, X_test, y_test)\n",
    "    results_tab[name] = metrics\n",
    "    cms_tab[name] = cm\n",
    "    print(\"\\n======\", name, \"======\")\n",
    "    print(metrics)\n",
    "    print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888bb45-4e5a-4155-953e-7d28ba161b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_test[:500].toarray() if hasattr(X_test, \"toarray\") else X_test[:500]\n",
    "\n",
    "for name in [\"RandomForest\", \"XGBoost\"]:\n",
    "    model = models_tab[name]\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_vals = explainer.shap_values(X_sample)\n",
    "    if isinstance(shap_vals, list):\n",
    "        shap_vals = shap_vals[1]\n",
    "\n",
    "    # Global\n",
    "    imp = np.abs(shap_vals).mean(axis=0)\n",
    "    df_imp = pd.DataFrame({\"feature\": feature_names, \"importance\": imp})\n",
    "    df_imp.sort_values(\"importance\", ascending=False).head(20)\n",
    "    display(df_imp.head(20))\n",
    "\n",
    "    # Local example\n",
    "    shap.initjs()\n",
    "    shap.force_plot(explainer.expected_value, shap_vals[0], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8269a7-9f91-44b5-b4a3-b3d756dc6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nfl_sequences(df, seq_len=8):\n",
    "    nfl = df[df[\"sport\"] == \"NFL\"].copy()\n",
    "    nfl = nfl.sort_values([\"player_id\", \"date\"])\n",
    "\n",
    "    feature_cols = [c for c in nfl.columns if c not in [\"player_id\", \"date\", \"future_injury_next_week\"]]\n",
    "\n",
    "    # One-hot categorical\n",
    "    cat = [c for c in feature_cols if nfl[c].dtype == 'object']\n",
    "    num = [c for c in feature_cols if c not in cat]\n",
    "\n",
    "    nfl = pd.get_dummies(nfl, columns=cat)\n",
    "    feature_cols = [c for c in nfl.columns if c not in [\"player_id\", \"date\", \"future_injury_next_week\"]]\n",
    "\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "\n",
    "    for pid, sub in nfl.groupby(\"player_id\"):\n",
    "        sub = sub.sort_values(\"date\")\n",
    "        Xmat = sub[feature_cols].values\n",
    "        y = sub[\"future_injury_next_week\"].values\n",
    "\n",
    "        if len(sub) < seq_len:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(sub) - seq_len + 1):\n",
    "            X_seq.append(Xmat[i:i+seq_len])\n",
    "            y_seq.append(y[i+seq_len-1])\n",
    "\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = build_nfl_sequences(df_eng, seq_len=8)\n",
    "len(X_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779059c-7b48-4a3b-b85c-d8b7c331eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bilstm(X, y):\n",
    "    if len(X) == 0:\n",
    "        print(\"Not enough NFL sequence data.\")\n",
    "        return None, None\n",
    "\n",
    "    n = len(X)\n",
    "    train_end = int(n * 0.7)\n",
    "    val_end = int(n * 0.85)\n",
    "\n",
    "    X_train, X_val, X_test = X[:train_end], X[train_end:val_end], X[val_end:]\n",
    "    y_train, y_val, y_test = y[:train_end], y[train_end:val_end], y[val_end:]\n",
    "\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(X.shape[1], X.shape[2])),\n",
    "        layers.Bidirectional(layers.LSTM(64)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    es = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=64, verbose=0, callbacks=[es])\n",
    "\n",
    "    y_proba = model.predict(X_test).ravel()\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_proba) if len(set(y_test)) > 1 else np.nan\n",
    "    }\n",
    "\n",
    "    return metrics, model\n",
    "\n",
    "\n",
    "bilstm_metrics, bilstm_model = train_bilstm(X_seq, y_seq)\n",
    "bilstm_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb021b-bad9-4231-bb57-fc691b4265a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== TABULAR MODEL PERFORMANCE =====\")\n",
    "for m, res in results_tab.items():\n",
    "    print(\"\\n\", m)\n",
    "    print(res)\n",
    "\n",
    "print(\"\\n===== BILSTM (NFL ONLY) =====\")\n",
    "print(bilstm_metrics)\n",
    "\n",
    "print(\"\\nPipeline complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
